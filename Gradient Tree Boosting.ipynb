{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58d28887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "316b1f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of Gradient Boost Regression\n",
    "# Weak learners are small trees. Loss function is half of sum of squared error.\n",
    "# Choice of loss reduces the gradient -dL(yi,F(xi))/dF(xi), F(x)=Fm-1(x) to a residual\n",
    "\n",
    "class GradientBoostingRegressor:\n",
    "    def __init__(self, learning_rate = 0.1, n_estimators = 100, max_depth_of_WL = 3):\n",
    "        self.nu = learning_rate\n",
    "        self.M = n_estimators\n",
    "        self.max_depth = max_depth_of_WL\n",
    "        self.F_array = []\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        F0 = lambda X: np.array([y.mean()] * len(X))\n",
    "        self.F_array.append(F0)\n",
    "        for m in range(1,self.M):\n",
    "            pseudo_residuals = y - self.predict(X)\n",
    "            Fm = WeakLearner(X, pseudo_residuals, self.max_depth)\n",
    "            self.F_array.append(Fm)\n",
    "  \n",
    "    def predict(self,X):\n",
    "        m = len(self.F_array)\n",
    "        predictions = self.F_array[0](X) + self.nu*sum(\n",
    "                    self.F_array[i].predict(X) for i in range(1,m))\n",
    "        return predictions\n",
    "\n",
    "class WeakLearner:\n",
    "    def __init__(self, X, error, max_depth = 3):\n",
    "        self.clf = DecisionTreeRegressor(max_depth = max_depth)\n",
    "        self.clf.fit(X, error)\n",
    "    def predict(self, X):\n",
    "        predictions = self.clf.predict(X)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21fad6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data = datasets.load_boston()\n",
    "X,y = scaler.fit_transform(data.data), data.target\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93e9a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse(f):\n",
    "    f.fit(X_train,y_train)\n",
    "    mse_val = mse(y_val,f.predict(X_val))\n",
    "    print(\"{:.1f}\".format(mse_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a42c4bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My GBR\n",
      "11.5\n",
      "sklearn RFC\n",
      "13.6\n",
      "sklearn GBR\n",
      "11.4\n"
     ]
    }
   ],
   "source": [
    "myGBR = GradientBoostingRegressor()\n",
    "print('My GBR')\n",
    "compute_mse(myGBR)\n",
    "from sklearn import ensemble\n",
    "\n",
    "skRFC = ensemble.RandomForestRegressor()\n",
    "print('sklearn RFC')\n",
    "compute_mse(skRFC)\n",
    "\n",
    "skGBR = ensemble.GradientBoostingRegressor(criterion = 'mse')\n",
    "print('sklearn GBR')\n",
    "compute_mse(skGBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aec51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Depending on the train/test split, the performance of the three models differ.\n",
    "## However in general, my GBR has comparable performance to the sklearn GBR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
